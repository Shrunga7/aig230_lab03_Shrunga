{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91489c36",
   "metadata": {},
   "source": [
    "# AIG230 NLP (Week 3 Lab) — Notebook 2: Statistical Language Models (Train, Test, Evaluate)\n",
    "\n",
    "This notebook focuses on **n-gram Statistical Language Models (SLMs)**:\n",
    "- Train **unigram**, **bigram**, **trigram** models\n",
    "- Handle **OOV** with `<UNK>`\n",
    "- Apply **smoothing** (Add-k)\n",
    "- Evaluate with **cross-entropy** and **perplexity**\n",
    "- Do **next-word prediction** and simple **text generation**\n",
    "\n",
    "> Industry framing: even if modern systems use neural LMs, n-gram LMs are still useful for\n",
    "baselines, constrained domains, and for understanding evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a046e",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ee526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc428b4",
   "metadata": {},
   "source": [
    "## 1) Data: domain text you might see in real systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d207e4c",
   "metadata": {},
   "source": [
    "We use short texts that resemble:\n",
    "- release notes\n",
    "- incident summaries\n",
    "- operational runbooks\n",
    "- customer support messaging\n",
    "\n",
    "In practice, you would load thousands to millions of lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb34582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 4,\n",
       " ['printer driver install fails with error 1603',\n",
       "  'push notifications not working on android app'],\n",
       " ['email delivery delayed messages queued',\n",
       "  'vpn disconnects frequently after windows update'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    \"vpn disconnects frequently after windows update\",\n",
    "    \"password reset link expired user cannot login\",\n",
    "    \"api requests timeout when latency spikes\",\n",
    "    \"portal returns 500 error after deployment\",\n",
    "    \"email delivery delayed messages queued\",\n",
    "    \"mfa prompt never arrives user stuck at login\",\n",
    "    \"wifi drops in meeting rooms access point reboot helps\",\n",
    "    \"outlook search not returning results index corrupted\",\n",
    "    \"printer driver install fails with error 1603\",\n",
    "    \"teams calls choppy audio jitter high\",\n",
    "    \"permission denied accessing shared drive though in correct group\",\n",
    "    \"battery drains fast after bios update power settings unchanged\",\n",
    "    \"push notifications not working on android app\",\n",
    "    \"mailbox full cannot receive emails auto archive not running\",\n",
    "]\n",
    "\n",
    "# Train/test split at sentence level\n",
    "random.seed(42) # Consistent output\n",
    "random.shuffle(corpus)\n",
    "split = int(0.75 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "len(train_texts), len(test_texts), train_texts[:2], test_texts[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9947",
   "metadata": {},
   "source": [
    "## 2) Tokenization + special tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c285f1d",
   "metadata": {},
   "source": [
    "We will:\n",
    "- lowercase\n",
    "- keep alphanumerics\n",
    "- split on whitespace\n",
    "- add sentence boundary tokens: `<s>` and `</s>`\n",
    "\n",
    "We will also map rare tokens to `<UNK>` based on training frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058f87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'printer',\n",
       " 'driver',\n",
       " 'install',\n",
       " 'fails',\n",
       " 'with',\n",
       " 'error',\n",
       " '1603',\n",
       " '</s>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split()\n",
    "\n",
    "def add_boundaries(tokens: List[str], n: int) -> List[str]:\n",
    "    # For n-grams, prepend (n-1) start tokens for simpler context handling\n",
    "    return [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(\"Printer driver install fails with error 1603\")\n",
    "add_boundaries(tokens, n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25308557",
   "metadata": {},
   "source": [
    "## 3) Build vocabulary and handle OOV with <UNK>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3338f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['email', 'delivery', 'delayed', 'messages', 'queued'],\n",
       " ['<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build vocab from training data\n",
    "train_tokens_flat = []\n",
    "for t in train_texts:\n",
    "    train_tokens_flat.extend(tokenize(t))\n",
    "\n",
    "freq = Counter(train_tokens_flat)\n",
    "\n",
    "# Typical practical rule: map tokens with frequency <= 1 to <UNK> in small corpora\n",
    "min_count = 2\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}\n",
    "\n",
    "def replace_oov(tokens: List[str], vocab: set) -> List[str]:\n",
    "    return [tok if tok in vocab else \"<UNK>\" for tok in tokens]\n",
    "\n",
    "# Show OOV effect\n",
    "sample = tokenize(test_texts[0])\n",
    "sample, replace_oov(sample, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759444a0",
   "metadata": {},
   "source": [
    "## 4) Train n-gram counts (unigram, bigram, trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eac8fa",
   "metadata": {},
   "source": [
    "We will compute:\n",
    "- `ngram_counts[(w1,...,wn)]`\n",
    "- `context_counts[(w1,...,w_{n-1})]`\n",
    "\n",
    "Then probability:\n",
    "\\ndefault:  P(w_n | context) = count(context + w_n) / count(context)\n",
    "\n",
    "This fails when an n-gram is unseen, so we add smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33672bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(tokens: list[str], n: int)-> list[tuple[str, ...]]:\n",
    "   return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def train_ngram_counts(texts: list[str], n: int, vocab: set) -> Dict[tuple[str, ...], int]:\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n)\n",
    "        for ng in get_ngrams(toks, n):\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "            \n",
    "    return ngram_counts, context_counts\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a4cb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<UNK>',): 67,\n",
       "         ('</s>',): 10,\n",
       "         ('not',): 3,\n",
       "         ('error',): 2,\n",
       "         ('after',): 2})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_counts, uni_ctx = train_ngram_counts(train_texts, n=1, vocab=vocab)\n",
    "uni_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786b489f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<UNK>', '<UNK>'): 51,\n",
       "         ('<s>', '<UNK>'): 10,\n",
       "         ('<UNK>', '</s>'): 10,\n",
       "         ('<UNK>', 'not'): 3,\n",
       "         ('not', '<UNK>'): 3,\n",
       "         ('<UNK>', 'error'): 2,\n",
       "         ('after', '<UNK>'): 2,\n",
       "         ('error', '<UNK>'): 1,\n",
       "         ('<UNK>', 'after'): 1,\n",
       "         ('error', 'after'): 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_counts, bi_ctx = train_ngram_counts(train_texts, n=2, vocab=vocab)\n",
    "bi_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06eeed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<UNK>', '<UNK>', '<UNK>'): 38,\n",
       "         ('<s>', '<s>', '<UNK>'): 10,\n",
       "         ('<s>', '<UNK>', '<UNK>'): 10,\n",
       "         ('<UNK>', '<UNK>', '</s>'): 7,\n",
       "         ('<UNK>', '<UNK>', 'not'): 3,\n",
       "         ('<UNK>', 'not', '<UNK>'): 3,\n",
       "         ('<UNK>', '<UNK>', 'error'): 2,\n",
       "         ('not', '<UNK>', '<UNK>'): 2,\n",
       "         ('<UNK>', 'error', '<UNK>'): 1,\n",
       "         ('error', '<UNK>', '</s>'): 1,\n",
       "         ('not', '<UNK>', '</s>'): 1,\n",
       "         ('<UNK>', '<UNK>', 'after'): 1,\n",
       "         ('<UNK>', 'after', '<UNK>'): 1,\n",
       "         ('after', '<UNK>', '<UNK>'): 1,\n",
       "         ('<UNK>', 'error', 'after'): 1,\n",
       "         ('error', 'after', '<UNK>'): 1,\n",
       "         ('after', '<UNK>', '</s>'): 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_counts, tri_ctx = train_ngram_counts(train_texts, n=3, vocab=vocab)\n",
    "tri_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ba7c8",
   "metadata": {},
   "source": [
    "## 5) Add-k smoothing and probability function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed806986",
   "metadata": {},
   "source": [
    "Add-k smoothing (a common baseline):\n",
    "\\na) Add *k* to every possible next word count  \n",
    "b) Normalize by context_count + k * |V|\n",
    "\n",
    "P_k(w|h) = (count(h,w) + k) / (count(h) + k*|V|)\n",
    "\n",
    "Where V is the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de565994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_addk(n_gram: tuple[str, ...], ngram_counts: Counter, context_counts: Counter, V: int, k: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Compute add-k P(w_n | w_1 ...w_{n-1})\n",
    "    where ngram = (w_1, w_2, ..., w_n)\n",
    "    0<k<=1\n",
    "    V is the vocabulary size\n",
    "    \"\"\"\n",
    "\n",
    "    context = n_gram[:-1]\n",
    "    return (ngram_counts[n_gram] + k) / (context_counts[context] + k * V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6a3bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038461538461538464"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = len(vocab)\n",
    "example = (\"<s>\", \"login\")\n",
    "prob_addk(example, bi_counts, bi_ctx, V, k=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6deec",
   "metadata": {},
   "source": [
    "## 6) Evaluate: cross-entropy and perplexity on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8426d9",
   "metadata": {},
   "source": [
    "We evaluate an LM by how well it predicts held-out text.\n",
    "\n",
    "Cross-entropy (average negative log probability):\n",
    "H = - (1/N) * sum log2 P(w_i | context)\n",
    "\n",
    "Perplexity:\n",
    "PP = 2^H\n",
    "\n",
    "Lower perplexity is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d03099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8224739937573902, 1.8712095221558307, 1.9552746520172761)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Perplexity: matrix that tells if a model is better or bad. Lower perplexity is the better\n",
    "# Evaluate perplexity on test set\n",
    "def evaluate_perplexity(texts: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k: float = 0.5) -> float:\n",
    "    V = len(vocab)\n",
    "    log2_probs = []\n",
    "    token_count = 0\n",
    "\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n)\n",
    "        ngrams = get_ngrams(toks, n)\n",
    "        for ng in ngrams:\n",
    "            p = prob_addk(ng, ngram_counts, context_counts, V, k=k)\n",
    "            log2_probs.append(math.log(p, 2))\n",
    "            token_count += 1\n",
    "\n",
    "    H = -sum(log2_probs) / token_count\n",
    "    PP = 2 ** H\n",
    "    return PP\n",
    "\n",
    "pp_uni = evaluate_perplexity(test_texts, n=1, ngram_counts=uni_counts, context_counts=uni_ctx, vocab=vocab, k=0.5)\n",
    "pp_bi  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab, k=0.5)\n",
    "pp_tri = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab, k=0.5)\n",
    "\n",
    "pp_uni, pp_bi, pp_tri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef338ce",
   "metadata": {},
   "source": [
    "## 7) Next-word prediction (top-k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d202f5",
   "metadata": {},
   "source": [
    "Given a context, compute the probability of each candidate next token and return the top-k.\n",
    "\n",
    "This mirrors:\n",
    "- autocomplete in constrained domains\n",
    "- template suggestion systems\n",
    "- command prediction in runbooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11363d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 0.8076923076923077),\n",
       " ('not', 0.038461538461538464),\n",
       " ('error', 0.038461538461538464),\n",
       " ('after', 0.038461538461538464),\n",
       " ('</s>', 0.038461538461538464)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def next_word_topk(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Given context tokens, return top-k next words with probabilities\n",
    "    using add-k smoothing.\n",
    "    \"\"\"\n",
    "        # Context length should be n-1\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    candidates = []\n",
    "    for w in vocab:\n",
    "        if w in {\"<s>\"}:\n",
    "            continue\n",
    "        ng = context + (w,)\n",
    "        p = prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth)\n",
    "        candidates.append((w, p))\n",
    "    candidates.sort(key=lambda x: -x[1])\n",
    "    return candidates[:top_k]\n",
    "\n",
    "# Bigram: context is 1 token\n",
    "next_word_topk([\"<s>\"], n=2, ngram_counts=bi_counts, context_counts=bi_ctx, vocab=vocab, top_k=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "957189f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 0.8076923076923077),\n",
       " ('not', 0.038461538461538464),\n",
       " ('error', 0.038461538461538464),\n",
       " ('after', 0.038461538461538464),\n",
       " ('</s>', 0.038461538461538464)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_topk([\"<s>\"], n=2, ngram_counts=bi_counts, context_counts=bi_ctx, vocab=vocab, k_smooth=0.5, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672e1e9",
   "metadata": {},
   "source": [
    "## 8) Simple generation (bigram or trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd41fb",
   "metadata": {},
   "source": [
    "Text generation is not the main goal in SLMs, but it helps you verify:\n",
    "- boundary handling\n",
    "- smoothing\n",
    "- OOV decisions\n",
    "\n",
    "We will sample tokens until we hit `</s>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8d1acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM: not <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "BIGRAM: <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> not <UNK> <UNK>\n",
      "BIGRAM: <UNK> <UNK> <UNK>\n",
      "BIGRAM: <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "BIGRAM: <UNK>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_next(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5):\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    words = [w for w in vocab if w != \"<s>\"]\n",
    "    probs = []\n",
    "    for w in words:\n",
    "        ng = context + (w,)\n",
    "        probs.append(prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth))\n",
    "    # Normalize\n",
    "    s = sum(probs)\n",
    "    probs = [p/s for p in probs]\n",
    "    return random.choices(words, weights=probs, k=1)[0]\n",
    "\n",
    "def generate(n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, max_len: int = 20, k_smooth: float = 0.5):\n",
    "    tokens = [\"<s>\"]*(n-1) if n > 1 else []\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        w = sample_next(tokens, n, ngram_counts, context_counts, vocab, k_smooth=k_smooth)\n",
    "        if w == \"</s>\":\n",
    "            break\n",
    "        out.append(w)\n",
    "        tokens.append(w)\n",
    "    return \" \".join(out)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"BIGRAM:\", generate(2, bi_counts, bi_ctx, vocab, max_len=18))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db5405",
   "metadata": {},
   "source": [
    "## 9) Model comparison: effect of n and smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7486afd",
   "metadata": {},
   "source": [
    "Try different `k` values. Notes:\n",
    "- `k=1.0` is Laplace smoothing (often too strong)\n",
    "- smaller `k` (like 0.1 to 0.5) is often better\n",
    "\n",
    "In real corpora, trigrams often beat bigrams, but require more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb25609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1.0:  bigram PP=1.95   trigram PP=2.09\n",
      "k= 0.5:  bigram PP=1.87   trigram PP=1.96\n",
      "k= 0.1:  bigram PP=1.79   trigram PP=1.80\n",
      "k=0.01:  bigram PP=1.76   trigram PP=1.75\n"
     ]
    }
   ],
   "source": [
    "for k in [1.0, 0.5, 0.1, 0.01]:\n",
    "    pp_bi_k  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab, k=k)\n",
    "    pp_tri_k = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab, k=k)\n",
    "    print(f\"k={k:>4}:  bigram PP={pp_bi_k:,.2f}   trigram PP={pp_tri_k:,.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be49abe",
   "metadata": {},
   "source": [
    "## Exercises (do these during lab)\n",
    "1) Add 20 more realistic domain sentences to the corpus and re-run training/evaluation.  \n",
    "2) Change `min_count` (OOV threshold) and explain how perplexity changes.  \n",
    "3) Implement **backoff**: if a trigram is unseen, fall back to bigram; if unseen, fall back to unigram.  \n",
    "4) Create a function that returns **top-5 next words** given a phrase like: `\"user cannot\"`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392673f",
   "metadata": {},
   "source": [
    "### 1. Add 20 more realistic domain sentences to the corpus and re-run training/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc272556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old corpus size: 14\n",
      "New corpus size: 34\n"
     ]
    }
   ],
   "source": [
    "more_sentences = [\n",
    "    \"vpn connection fails after router reboot\",\n",
    "    \"user cannot login account locked out\",\n",
    "    \"password reset email not received by user\",\n",
    "    \"api returns 403 forbidden after token refresh\",\n",
    "    \"portal page loads slow during peak hours\",\n",
    "    \"email inbox not syncing on mobile device\",\n",
    "    \"mfa code expires too quickly user complains\",\n",
    "    \"wifi signal weak in conference room corner\",\n",
    "    \"printer not detected after driver update\",\n",
    "    \"teams video freezes when bandwidth drops\",\n",
    "    \"shared drive access denied for new employee\",\n",
    "    \"laptop battery not charging after bios update\",\n",
    "    \"android app crashes when opening notifications\",\n",
    "    \"mailbox storage quota exceeded cannot send email\",\n",
    "    \"outlook keeps asking for password repeatedly\",\n",
    "    \"network latency high after firewall change\",\n",
    "    \"dns server not responding intermittently\",\n",
    "    \"user session times out too fast on portal\",\n",
    "    \"deployment caused database connection errors\",\n",
    "    \"messages delayed in queue after service restart\",\n",
    "]\n",
    "\n",
    "corpus2 = corpus + more_sentences\n",
    "print(\"Old corpus size:\", len(corpus))\n",
    "print(\"New corpus size:\", len(corpus2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db5bfed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(corpus2)\n",
    "split = int(0.75 * len(corpus2))\n",
    "train_texts = corpus2[:split]\n",
    "test_texts  = corpus2[split:]\n",
    "\n",
    "len(train_texts), len(test_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e562785",
   "metadata": {},
   "source": [
    "**Build Vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8db31e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['wifi', 'signal', 'weak', 'in', 'conference', 'room', 'corner'],\n",
       " ['<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build vocab from training data\n",
    "train_tokens_flat = []\n",
    "for t in train_texts:\n",
    "    train_tokens_flat.extend(tokenize(t))\n",
    "\n",
    "freq = Counter(train_tokens_flat)\n",
    "\n",
    "# Typical practical rule: map tokens with frequency <= 1 to <UNK> in small corpora\n",
    "min_count = 2\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}\n",
    "\n",
    "def replace_oov(tokens: List[str], vocab: set) -> List[str]:\n",
    "    return [tok if tok in vocab else \"<UNK>\" for tok in tokens]\n",
    "\n",
    "# Show OOV effect\n",
    "sample = tokenize(test_texts[0])\n",
    "sample, replace_oov(sample, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd23fc6",
   "metadata": {},
   "source": [
    "**Train n-gram Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb50c18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 91, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ngrams(tokens: List[str], n: int) -> List[Tuple[str, ...]]:\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def train_ngram_counts(texts: List[str], n: int, vocab: set) -> Tuple[Counter, Counter]:\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n)\n",
    "        for ng in get_ngrams(toks, n):\n",
    "            ngram_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "    return ngram_counts, context_counts\n",
    "\n",
    "uni_counts, uni_ctx = train_ngram_counts(train_texts, n=1, vocab=vocab)\n",
    "bi_counts, bi_ctx   = train_ngram_counts(train_texts, n=2, vocab=vocab)\n",
    "tri_counts, tri_ctx = train_ngram_counts(train_texts, n=3, vocab=vocab)\n",
    "\n",
    "len(uni_counts), len(bi_counts), len(tri_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba1486",
   "metadata": {},
   "source": [
    "**Evaluate cross entrpoy and perplexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bd9d4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.654585664417506, 4.430566853721905, 6.338462532560499)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_perplexity(texts: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k: float = 0.5) -> float:\n",
    "    V = len(vocab)\n",
    "    log2_probs = []\n",
    "    token_count = 0\n",
    "\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n)\n",
    "        ngrams = get_ngrams(toks, n)\n",
    "        for ng in ngrams:\n",
    "            p = prob_addk(ng, ngram_counts, context_counts, V, k=k)\n",
    "            log2_probs.append(math.log(p, 2))\n",
    "            token_count += 1\n",
    "\n",
    "    H = -sum(log2_probs) / token_count\n",
    "    PP = 2 ** H\n",
    "    return PP\n",
    "\n",
    "pp_uni = evaluate_perplexity(test_texts, n=1, ngram_counts=uni_counts, context_counts=uni_ctx, vocab=vocab, k=0.5)\n",
    "pp_bi  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab, k=0.5)\n",
    "pp_tri = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab, k=0.5)\n",
    "\n",
    "pp_uni, pp_bi, pp_tri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06999afb",
   "metadata": {},
   "source": [
    "**Obseveration**  \n",
    "After adding 20 more sentences, the model usually gets better at predicting test text, so perplexity often decreases because it has seen more patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47c4d9",
   "metadata": {},
   "source": [
    "### 2)  Change `min_count` (OOV threshold) and explain how perplexity changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b91403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_count=1 | Vocab size=121 | PP uni=194.10, bi=122.04, tri=122.63\n",
      "min_count=2 | Vocab size=33 | PP uni=3.65, bi=4.43, tri=6.34\n",
      "min_count=3 | Vocab size=12 | PP uni=2.43, bi=2.54, tri=2.75\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(train_texts, min_count):\n",
    "    train_tokens_flat = []\n",
    "    for t in train_texts:\n",
    "        train_tokens_flat.extend(tokenize(t))\n",
    "    freq = Counter(train_tokens_flat)\n",
    "\n",
    "    vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "    vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}\n",
    "    return vocab\n",
    "\n",
    "for mc in [1, 2, 3]:\n",
    "    vocab_mc = build_vocab(train_texts, min_count=mc)\n",
    "\n",
    "    uni_counts, uni_ctx = train_ngram_counts(train_texts, n=1, vocab=vocab_mc)\n",
    "    bi_counts, bi_ctx   = train_ngram_counts(train_texts, n=2, vocab=vocab_mc)\n",
    "    tri_counts, tri_ctx = train_ngram_counts(train_texts, n=3, vocab=vocab_mc)\n",
    "\n",
    "    pp_uni = evaluate_perplexity(test_texts, n=1, ngram_counts=uni_counts, context_counts=uni_ctx, vocab=vocab_mc, k=0.5)\n",
    "    pp_bi  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab_mc, k=0.5)\n",
    "    pp_tri = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab_mc, k=0.5)\n",
    "\n",
    "    print(f\"min_count={mc} | Vocab size={len(vocab_mc)} | PP uni={pp_uni:.2f}, bi={pp_bi:.2f}, tri={pp_tri:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6eb1b6",
   "metadata": {},
   "source": [
    "**Explanations**:  \n",
    "When min_count =1 , Vocab size = 121\n",
    "All words are kept, including many rare ones. The model sees many words only once, so it cannot predict them well in the test set. This leads to very high perplexity.  \n",
    "\n",
    "When min_count =2 , Vocab size = 33\n",
    "Rare words are mapped to UNK reducing sparsity. Model now can see more repeated patterns and hence can make better predictions with lower perplexity around 3-6.\n",
    "\n",
    "When min_count =3 , Vocab size = 12\n",
    "Most of the words are replaced by UNK. Hence model can see all most common tokens, resulting in very low perplexity, less surprising text and easy predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a43fcc",
   "metadata": {},
   "source": [
    "### 3) Implement backoff (tri → bi → uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "860ec823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_backoff(context_tokens, word,\n",
    "                 uni_counts, uni_ctx,\n",
    "                 bi_counts, bi_ctx,\n",
    "                 tri_counts, tri_ctx,\n",
    "                 vocab, k=0.5):\n",
    "    V = len(vocab)\n",
    "\n",
    "    # Try trigram if we have >=2 context tokens\n",
    "    if len(context_tokens) >= 2:\n",
    "        ng3 = (context_tokens[-2], context_tokens[-1], word)\n",
    "        ctx3 = ng3[:-1]\n",
    "        if tri_ctx[ctx3] > 0:\n",
    "            return prob_addk(ng3, tri_counts, tri_ctx, V, k=k)\n",
    "\n",
    "    # Try bigram if we have >=1 context token\n",
    "    if len(context_tokens) >= 1:\n",
    "        ng2 = (context_tokens[-1], word)\n",
    "        ctx2 = ng2[:-1]\n",
    "        if bi_ctx[ctx2] > 0:\n",
    "            return prob_addk(ng2, bi_counts, bi_ctx, V, k=k)\n",
    "\n",
    "    # Fall back to unigram\n",
    "    ng1 = (word,)\n",
    "    return prob_addk(ng1, uni_counts, uni_ctx, V, k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15199b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backoff perplexity: 3.6673595129423933\n"
     ]
    }
   ],
   "source": [
    "def evaluate_perplexity_backoff(texts, vocab, k=0.5):\n",
    "    log2_probs = []\n",
    "    token_count = 0\n",
    "\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n=3)  # use trigram boundaries\n",
    "        for i in range(2, len(toks)):\n",
    "            context = toks[i-2:i]\n",
    "            word = toks[i]\n",
    "            p = prob_backoff(context, word, uni_counts, uni_ctx, bi_counts, bi_ctx, tri_counts, tri_ctx, vocab, k=k)\n",
    "            log2_probs.append(math.log(p, 2))\n",
    "            token_count += 1\n",
    "\n",
    "    H = -sum(log2_probs) / token_count\n",
    "    return 2 ** H\n",
    "\n",
    "pp_backoff = evaluate_perplexity_backoff(test_texts, vocab=vocab, k=0.5)\n",
    "print(\"Backoff perplexity:\", pp_backoff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a549853",
   "metadata": {},
   "source": [
    "### 4) Create a function that returns **top-5 next words** given a phrase like: `\"user cannot\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca6bf6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('login', 0.13513513513513514),\n",
       " ('for', 0.02702702702702703),\n",
       " ('outlook', 0.02702702702702703),\n",
       " ('on', 0.02702702702702703),\n",
       " ('out', 0.02702702702702703)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def next_word_top5_backoff(phrase: str, vocab: set, k=0.5, top_k=5):\n",
    "    toks = replace_oov(tokenize(phrase), vocab)\n",
    "\n",
    "    # Use trigram-style context: last 2 words, pad with <s> if needed\n",
    "    context = [\"<s>\", \"<s>\"] + toks\n",
    "    context = context[-2:]\n",
    "\n",
    "    candidates = []\n",
    "    for w in vocab:\n",
    "        if w == \"<s>\":\n",
    "            continue\n",
    "        p = prob_backoff(context, w, uni_counts, uni_ctx, bi_counts, bi_ctx, tri_counts, tri_ctx, vocab, k=k)\n",
    "        candidates.append((w, p))\n",
    "\n",
    "    candidates.sort(key=lambda x: -x[1])\n",
    "    return candidates[:top_k]\n",
    "\n",
    "next_word_top5_backoff(\"user cannot\", vocab=vocab, k=0.5, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aig230-env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
